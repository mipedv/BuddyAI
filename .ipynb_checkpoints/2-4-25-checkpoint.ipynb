{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db28d83f-1290-4712-9a80-5e272f928152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python: D:\\LONGSPUR\\TASK\\AI_buddy_model\\buddyvenv\\Scripts\\python.exe\n",
      "Virtual Env: D:\\LONGSPUR\\TASK\\AI_buddy_model\\buddyvenv\n",
      "Working Dir: D:\\LONGSPUR\\TASK\\AI_buddy_model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "print(f\"\"\"\n",
    "Python: {sys.executable}\n",
    "Virtual Env: {sys.prefix}\n",
    "Working Dir: {os.getcwd()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682e529a-275e-4a1f-b09d-1075af280fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LONGSPUR\\TASK\\AI_buddy_model\\buddyvenv\\Lib\\site-packages\\pandas\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__file__)  # Should show buddyvenv path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1f9ff1-c708-4b7b-ac76-a519fdba4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2163967-2d95-4273-aa0e-261966d0bc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --force-reinstall python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71046d2c-ef8a-402b-990c-f5dcfe4aafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a0f2a9-7f45-4aa3-9193-a9c2a0c4093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')  \n",
    "if openai_api_key:\n",
    "    print(\"API key loaded successfully!\")\n",
    "else:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf98451f-4a29-4b55-b697-755fd890ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.70.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: D:\\LONGSPUR\\TASK\\AI_buddy_model\\buddyvenv\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: langchain-openai\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc71bb9-4766-4c64-9c2f-702197087420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "#from langchain_core.documents import Document\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c797f683-cec8-4e79-978f-ccddf3e9c45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca32697-d82a-42a4-a9f2-e80716808460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18f8d74-85b2-41f6-be51-1dd20c773a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.preprocess_pdf import extract_text_from_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf3824c-e46e-4a69-a2b9-d588af160902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyond Earth12Chapter\n",
      "Nubra is a beautiful region in Ladakh. An eleven-year old \n",
      "girl Yangdol and he\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_path = os.path.join(\"knowledge-base\", \"textbook.pdf\")\n",
    "pdf_path = os.path.abspath(base_path) \n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "if text:\n",
    "    print(text[:100])\n",
    "else:\n",
    "    print(\"No text extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec6c42a7-f550-4477-9875-47320c63f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_ADVANCED = False  \n",
    "MODEL = \"gpt-4o-mini\" if USE_ADVANCED else \"gpt-3.5-turbo\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "818bb03f-f400-437f-8c8a-3179185ea9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff3c4f09-0dfb-4110-ac49-c879bc83337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     D:\\LONGSPUR\\TASK\\AI_buddy_model\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk_data_dir = \"D:\\\\LONGSPUR\\\\TASK\\\\AI_buddy_model\\\\nltk_data\"\n",
    "nltk.download('punkt', download_dir=nltk_data_dir)\n",
    "nltk.data.path.append(nltk_data_dir)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69a33c8-8de6-48fd-889a-7414fb218eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiktoken import encoding_for_model\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0013c404-24bd-4200-9598-e4f88ac29b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 9\n",
      "First Chunk:\n",
      "{'text': 'Beyond Earth12Chapter Nubra is a beautiful region in Ladakh. An eleven-year old  girl Yangdol and her twin brother Dorjay live in one of the villages of this region. They love their  surroundingsâ€”the majestic mountain peaks, and the glaciers, but their favourite is the night sky when the entire sky is lit up with thousands of stars (Fig. 12.1). The weather in Nubra is almost cloudless. With almost no air or light pollution, the night sky is very clearly visible. Night after night, Yangdol and Dorjay observe the stars and experience an immense sense of awe. Fig. 12.1: The beauty of night sky from a very dark  location in Ladakh, India Nubra in Ladakh, India Chapter 12.indd   231 10-07-2024   18:13:26  Curiosity | Textbook of Science | Grade 6 232Growing up, Yangdol and Dorjay have been hearing  interesting stories about stars from their elders. They have  heard how some particular stars in the clear skies helped the caravans passing through Nubra in finding direction in the ancient days. They wonder how far away and how big the stars are. They also enjoy trying to find some patterns among the stars that remind them of familiar objects. Have you ever looked at the stars in the night sky and tried to connect them with imaginary lines, just like dots and lines in a drawing? Activity 12.1: Let us draw  \\x8bFig. 12.2 shows bright stars in one part of the night sky. \\x8bLook at it carefully and try to imagine a pattern formed by a group of stars. \\x8bDraw lines to connect the stars and make the pattern. \\x8bThink of an animal or an object that is similar to the pattern drawn by you. Write its name near your pattern.12.1 Stars and Constellations At night, when we look up at the sky, we see many stars. Some stars are bright and others  are dim. Stars shine with their own light. Some groups of stars appear to form  patterns which are like shapes of familiar things. Long ago, when watching stars in the night sky was a favourite pastime of our ancestors, they identified these star patterns with animals, things or characters in stories. Many cultures had names for patterns based on their own stories. These imaginary shapes helped them in recognising stars in the sky. Recognising stars and their patterns was a useful skill  for navigation in the olden times. Before the arrival of modern technology or even before the invention of the magnetic compass, it helped people, particularly sailors and travellers, in finding directions at sea or on land. It is still used in emergencies as a backup method. In earlier times, groups of stars forming patterns were  called constellations. Currently, the regions of sky, which include these groups of stars, are defined as constellations. However , since in constellations, the patterns of stars are often the most prominent, the term constellation is still  commonly used for these groups of stars. Fig. 12.2: A part of the night sky  \\x8bRepeat the above steps and make some more patterns. \\x8bNow think of an interesting story about your patterns. Compare your  patterns with the patterns drawn by your friends. Are the patterns same or different? Narrate your story to others and listen to their stories. Do you notice that everyoneâ€™s patterns, names and stories are different? Is it not fun? Chapter 12.indd   232 10-07-2024   18:13:27 Beyond Earth233Growing up, Yangdol and Dorjay have been hearing  interesting stories about stars from their elders. They have  heard how some particular stars in the clear skies helped the caravans passing through Nubra in finding direction in the ancient days. They wonder how far away and how big the stars are. They also enjoy trying to find some patterns among the stars that remind them of familiar objects. Have you ever looked at the stars in the night sky and tried to connect them with imaginary lines, just like dots and lines in a drawing? Activity 12.1: Let us draw  \\x8bFig. 12.2 shows bright stars in one part of the night sky. \\x8bLook at it carefully and try to imagine a pattern formed by a group of stars. \\x8bDraw lines to connect the stars and make the pattern. \\x8bThink of an animal or an object that is similar to the pattern drawn by you. Write its name near your pattern.12.1 Stars and Constellations At night, when we look up at the sky, we see  many stars. Some stars are bright and others  are dim. Stars shine with their own light.', 'tokens': 988, 'chunk_id': 0, 'page_number': 1}\n"
     ]
    }
   ],
   "source": [
    "from scripts.chunking import dynamic_chunking_with_metadata\n",
    "chunks = dynamic_chunking_with_metadata(text, token_limit=1000, model=\"cl100k_base\",page_number=1)\n",
    "print(f\"Total Chunks: {len(chunks)}\")\n",
    "print(\"First Chunk:\")\n",
    "print(chunks[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f75cf76-73f9-431d-828a-b29381c9ba5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>Beyond Earth12Chapter Nubra is a beautiful reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>963</td>\n",
       "      <td>Some groups of stars appear to form  patterns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>970</td>\n",
       "      <td>12.4: Big Dipper , Little Dipper  and Pole Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>996</td>\n",
       "      <td>Activity 12.3: Let us try to identify   Â‹In In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>More to  know! There are many more objects  in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>958</td>\n",
       "      <td>Many Higher Education  Institutions conduct ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>996</td>\n",
       "      <td>Few other comets get broken up, or fall into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>978</td>\n",
       "      <td>(ii)  Make two similar riddles b y yourself. 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>359</td>\n",
       "      <td>Chapter 12.indd   252 10-07-2024   18:20:23 It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Chunk ID  Tokens                                            Preview\n",
       "0         0     988  Beyond Earth12Chapter Nubra is a beautiful reg...\n",
       "1         1     963  Some groups of stars appear to form  patterns ...\n",
       "2         2     970  12.4: Big Dipper , Little Dipper  and Pole Sta...\n",
       "3         3     996  Activity 12.3: Let us try to identify   Â‹In In...\n",
       "4         4    1000  More to  know! There are many more objects  in...\n",
       "5         5     958  Many Higher Education  Institutions conduct ni...\n",
       "6         6     996  Few other comets get broken up, or fall into t...\n",
       "7         7     978  (ii)  Make two similar riddles b y yourself. 3...\n",
       "8         8     359  Chapter 12.indd   252 10-07-2024   18:20:23 It..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Total Chunks: 9\n",
      "ðŸ”  Total Tokens: 8208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def visualize_chunks(chunks):\n",
    "    df = pd.DataFrame([{\n",
    "        \"Chunk ID\": c[\"chunk_id\"],\n",
    "        \"Tokens\": c[\"tokens\"],\n",
    "        \"Preview\": c[\"text\"][:100] + \"...\" if len(c[\"text\"]) > 100 else c[\"text\"]\n",
    "    } for c in chunks])\n",
    "\n",
    "    display(df)\n",
    "    print(f\"ðŸ“¦ Total Chunks: {len(chunks)}\")\n",
    "    print(f\"ðŸ”  Total Tokens: {sum(c['tokens'] for c in chunks)}\")\n",
    "\n",
    "visualize_chunks(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01471483-854a-4f59-a82b-21fbd2063fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade chromadb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23279b09-fbe4-4fe9-8d07-e00aa9890efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b29d835a-2b27-480c-bd91-b04e9d3139b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de5e6870-e994-42ec-8007-fea82f77dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aaad616-39a2-4876-b033-b4e1fec73ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "âš ï¸ ChromaDB exists at 'vector_db'. Do you want to delete it? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Skipped deletion. Existing DB will be reused.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    confirm = input(f\"âš ï¸ ChromaDB exists at '{db_name}'. Do you want to delete it? (y/n): \")\n",
    "    if confirm.lower() == \"y\":\n",
    "        Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "        print(f\"ðŸ—‘ï¸ ChromaDB at '{db_name}' has been deleted.\")\n",
    "    else:\n",
    "        print(\"âŒ Skipped deletion. Existing DB will be reused.\")\n",
    "else:\n",
    "    print(f\"âœ… No existing ChromaDB found at '{db_name}'. Starting fresh.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dad69b3-9922-4fa8-9331-ff4854d00188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b9089c-76c1-4aa8-8acf-92e70f1a435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 9 LangChain Documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=chunk[\"text\"],\n",
    "        metadata={\n",
    "            \"chunk_id\": chunk[\"chunk_id\"],\n",
    "            \"page_number\": chunk[\"page_number\"],\n",
    "            \"tokens\": chunk[\"tokens\"]  # Optional: track token count\n",
    "        }\n",
    "    )\n",
    "    for chunk in chunks\n",
    "]\n",
    "\n",
    "print(f\"âœ… Created {len(documents)} LangChain Documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5679f1d6-5a31-4faf-a9dd-3327afc825b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Documents added to ChromaDB successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_directory = \"./vector_db\"\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./vector_db\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"âœ… Documents added to ChromaDB successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe13920a-b36f-4b63-b982-a3c650b250e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-openai chromadb openai tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b56bac8-7334-4816-aa17-24220b02ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install rank_bm25 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c41a1a9-1eed-4c8a-929f-e5e272d41ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 3\n",
    "vector_retriever = vectorstore.as_retriever()\n",
    "vector_retriever.search_kwargs['k'] = 3\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.5, 0.5]  # You can tune this ratio\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c724c82-b4d7-458c-827d-27943b9fc62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "759f8079-3d0c-4b2c-93ef-09b0f2f1846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irfan\\AppData\\Local\\Temp\\ipykernel_34544\\1453458743.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o-mini\")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=hybrid_retriever,\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1833e9ce-73a4-4a89-95bf-07a2a2e3296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not mention whether the PDF contains an image representation of the solar system. Therefore, I don't know if it does or not.\n"
     ]
    }
   ],
   "source": [
    "query = \"is pdf contains image representation of solar system\"\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3929e23-57d6-443e-9406-ba1318ac7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    \"textbook\": \"Give a simple, 6th-grade level explanation suitable for a school science book:\",\n",
    "    \"detailed\": \"Explain this in a detailed, step-by-step way using analogies and real-world examples, but still keep it easy to understand:\",\n",
    "    \"advanced\": \"Now go beyond textbook knowledge. Give a deeper, insightful explanation that includes scientific reasoning, historical background, or real-world applications. Assume the reader is curious and intelligent.\"\n",
    "}\n",
    "\n",
    "\n",
    "def build_prompt(question, level):\n",
    "    # Clean the input\n",
    "    question = str(question).strip()\n",
    "    prompt_prefix = PROMPTS.get(level, PROMPTS[\"textbook\"])  # Default to textbook if invalid level\n",
    "    \n",
    "    # Build the complete prompt\n",
    "    full_prompt = f\"{prompt_prefix} {question}\"\n",
    "    \n",
    "    return full_prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dcc0c74-1e09-4266-a092-5d8577fff89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUGGEST_QUESTIONS_PROMPT = \"\"\"You're a helpful learning assistant.\n",
    "\n",
    "Based on the following answer, generate 3 thoughtful follow-up questions a 6th-grade student might ask next. Format each question on a new line:\n",
    "\n",
    "Answer:\n",
    "{content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7a2ebaa-5d0e-48db-ad10-cebd94463f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87a60515-eed5-41fb-83f2-23f21f34b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suggested_questions(content):\n",
    "    try:\n",
    "        prompt = SUGGEST_QUESTIONS_PROMPT.format(content=str(content).strip())\n",
    "        \n",
    "        llm = ChatOpenAI(\n",
    "            temperature=0.7,\n",
    "            model=\"gpt-3.5-turbo\",  # Make sure this matches your available model\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        # Clean and process suggestions\n",
    "        suggestions = response.content.strip().split(\"\\n\")\n",
    "        cleaned = [\n",
    "            s.strip(\" -â€¢123.\").strip()\n",
    "            for s in suggestions\n",
    "            if s.strip() and len(s.strip()) > 5\n",
    "        ]\n",
    "        \n",
    "        # Ensure we always return exactly 3 suggestions\n",
    "        while len(cleaned) < 3:\n",
    "            cleaned.append(\"\")\n",
    "            \n",
    "        return cleaned[:3]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating suggestions: {str(e)}\")\n",
    "        return [\"\", \"\", \"\"]  # Return empty suggestions on error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48d9529d-88fc-4a21-99e9-7322b86abe07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“© User question: What is a constellation?\n",
      "ðŸŽ¯ Level: textbook\n",
      "ðŸ“˜ Using textbook retriever\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irfan\\AppData\\Local\\Temp\\ipykernel_34544\\545500202.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“© User question: How were constellations named and identified by different cultures?\n",
      "ðŸŽ¯ Level: textbook\n",
      "ðŸ“˜ Using textbook retriever\n",
      "ðŸ“© User question: How were constellations named and identified by different cultures?\n",
      "ðŸŽ¯ Level: detailed\n",
      "ðŸ“— Simplifying PDF-based answer using LLM\n",
      "Alright, so imagine looking up at the night sky and seeing lots of stars. Some people a long time ago noticed that some stars formed patterns that looked like things they knew, like animals or people. They gave these patterns names and made up stories about them based on their own beliefs and traditions. This helped them remember where the stars were and navigate their way around without maps or GPS like we have today. Different cultures had their own names and stories for the star patterns, which is why we have different constellations. It's like each culture had its own special way of understanding the stars and using them to guide them.ðŸ“© User question: How were constellations named and identified by different cultures?\n",
      "ðŸŽ¯ Level: advanced\n",
      "ðŸ“• Direct LLM (no PDF) with depth\n",
      "Constellations were named and identified by different cultures through a combination of mythology, cultural beliefs, and celestial observations. \n",
      "\n",
      "In ancient times, cultures around the world looked up at the night sky and saw patterns of stars that they believed represented gods, heroes, animals, and other figures from their myths and legends. They often connected these celestial patterns with stories from their culture's oral traditions, creating a mythology that explained the origins and meanings of the constellations.\n",
      "\n",
      "For example, in Greek mythology, the constellation Orion is said to represent a mighty hunter who was placed in the sky by the gods after his death. The stars that make up Orion's belt and sword are easily recognizable in the night sky, and the story of Orion has been passed down through generations as a way to explain the constellation's name and significance.\n",
      "\n",
      "Similarly, the Chinese zodiac is based on a system of constellations that represent different animals, each of which is associated with certain personality traits and characteristics. The Chinese have been observing the stars for thousands of years, and their interpretations of the constellations have been passed down through generations as part of their cultural heritage.\n",
      "\n",
      "In modern times, constellations are officially recognized and named by organizations like the International Astronomical Union (IAU), which establishes the names and boundaries of constellations based on scientific criteria. However, many of the traditional names and stories associated with constellations are still widely known and celebrated by cultures around the world.\n",
      "\n",
      "Fun fact: The word \"constellation\" comes from the Latin word \"constellatio,\" which means \"set of stars.\" The ancient Greeks were the first to divide the night sky into distinct constellations, and many of the names they gave to these star patterns are still in use today."
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def chat_stream(message, history, level):\n",
    "    if not message or len(message.strip()) < 4:\n",
    "        yield \"ðŸ™ Please ask a proper question so I can help!\", history, message\n",
    "\n",
    "    print(f\"ðŸ“© User question: {message}\")\n",
    "    print(f\"ðŸŽ¯ Level: {level}\")\n",
    "\n",
    "    try:\n",
    "        if level == \"textbook\":\n",
    "            print(\"ðŸ“˜ Using textbook retriever\")\n",
    "            result = conversation_chain.invoke({\n",
    "                \"question\": message,\n",
    "                \"chat_history\": history\n",
    "            })\n",
    "            answer = result[\"answer\"]\n",
    "            history.append((message, answer))\n",
    "            yield answer, history, message\n",
    "\n",
    "        elif level == \"detailed\":\n",
    "            print(\"ðŸ“— Simplifying PDF-based answer using LLM\")\n",
    "            base_result = conversation_chain.invoke({\n",
    "                \"question\": message,\n",
    "                \"chat_history\": history\n",
    "            })\n",
    "            base_answer = base_result[\"answer\"]\n",
    "            history.append((message, base_answer))\n",
    "\n",
    "            llm = ChatOpenAI(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                streaming=True,\n",
    "                temperature=0.5,\n",
    "                openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                callbacks=[StreamingStdOutCallbackHandler()]\n",
    "            )\n",
    "\n",
    "            final_answer = \"\"\n",
    "            for chunk in llm.stream([HumanMessage(content=f\"Explain this like you're teaching a 6th grader:\\n{base_answer}\")]):\n",
    "                final_answer += chunk.content\n",
    "                yield final_answer, history, message\n",
    "\n",
    "        elif level == \"advanced\":\n",
    "            print(\"ðŸ“• Direct LLM (no PDF) with depth\")\n",
    "            llm = ChatOpenAI(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                streaming=True,\n",
    "                temperature=0.7,\n",
    "                openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                callbacks=[StreamingStdOutCallbackHandler()]\n",
    "            )\n",
    "\n",
    "            final_answer = \"\"\n",
    "            for chunk in llm.stream([HumanMessage(content=f\"Explain this with real-world insights and fun facts:\\n{message}\")]):\n",
    "                final_answer += chunk.content\n",
    "                yield final_answer, history, message\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ERROR: {e}\")\n",
    "        yield f\"âš ï¸ Something went wrong: {e}\", history, message\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks(css=\"\"\"\n",
    "body {\n",
    "    background-color: #121212;\n",
    "    font-family: 'Segoe UI', sans-serif;\n",
    "}\n",
    "\n",
    ".gr-button {\n",
    "    font-size: 16px !important;\n",
    "    padding: 14px !important;\n",
    "    border-radius: 10px;\n",
    "}\n",
    "\n",
    ".gr-button-primary {\n",
    "    background-color: #4CAF50 !important;\n",
    "    color: white !important;\n",
    "}\n",
    "\n",
    ".suggested-btn {\n",
    "    width: 100% !important;\n",
    "    margin-top: 10px !important;\n",
    "    background-color: #e8eaf6 !important;\n",
    "    color: #1a237e !important;\n",
    "    padding: 16px !important;\n",
    "    text-align: left !important;\n",
    "    font-size: 16px !important;\n",
    "    font-weight: 500 !important;\n",
    "    border: none !important;\n",
    "    box-shadow: 0px 1px 3px rgba(0,0,0,0.1);\n",
    "    transition: background-color 0.2s ease;\n",
    "}\n",
    "\n",
    ".suggested-btn:hover {\n",
    "    background-color: #d1d9ff !important;\n",
    "}\n",
    "\"\"\") as demo:\n",
    "\n",
    "    gr.Markdown(\"### ðŸ‘‹ Welcome to Buddy AI: Your Learning Companion\")\n",
    "\n",
    "    question = gr.Textbox(label=\"Ask your question ðŸ‘‡\", lines=1, elem_id=\"question-box\")\n",
    "    level = gr.Dropdown(choices=[\"textbook\", \"detailed\", \"advanced\"], value=\"textbook\", label=\"Answer Level ðŸŽ¯\")\n",
    "    answer_box = gr.Textbox(label=\"ðŸ§  Buddy's Answer\", lines=8, interactive=False)\n",
    "    state = gr.State([])\n",
    "\n",
    "    # States to store suggested question texts\n",
    "    suggested_q1 = gr.State()\n",
    "    suggested_q2 = gr.State()\n",
    "    suggested_q3 = gr.State()\n",
    "\n",
    "    # Suggested question buttons\n",
    "    suggest_btn1 = gr.Button(visible=False, interactive=True, elem_classes=\"suggested-btn\")\n",
    "    suggest_btn2 = gr.Button(visible=False, interactive=True, elem_classes=\"suggested-btn\")\n",
    "    suggest_btn3 = gr.Button(visible=False, interactive=True, elem_classes=\"suggested-btn\")\n",
    "\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\", elem_classes=\"gr-button-primary\")\n",
    "        clear_btn = gr.Button(\"Clear\")\n",
    "\n",
    "    # Streaming chatbot with generator\n",
    "    chat_event = submit_btn.click(\n",
    "        fn=chat_stream,\n",
    "        inputs=[question, state, level],\n",
    "        outputs=[answer_box, state, question],\n",
    "        api_name=\"chat_stream\"\n",
    "    )\n",
    "\n",
    "    # ðŸ” Post-answer: generate suggested questions\n",
    "    def suggest_followups(answer):\n",
    "        suggestions = generate_suggested_questions(answer)\n",
    "        s1 = gr.update(value=suggestions[0], visible=True) if len(suggestions) > 0 else gr.update(visible=False)\n",
    "        s2 = gr.update(value=suggestions[1], visible=True) if len(suggestions) > 1 else gr.update(visible=False)\n",
    "        s3 = gr.update(value=suggestions[2], visible=True) if len(suggestions) > 2 else gr.update(visible=False)\n",
    "        return (\n",
    "            s1, s2, s3,\n",
    "            suggestions[0] if len(suggestions) > 0 else \"\",\n",
    "            suggestions[1] if len(suggestions) > 1 else \"\",\n",
    "            suggestions[2] if len(suggestions) > 2 else \"\"\n",
    "        )\n",
    "\n",
    "    chat_event.then(\n",
    "        fn=suggest_followups,\n",
    "        inputs=[answer_box],\n",
    "        outputs=[suggest_btn1, suggest_btn2, suggest_btn3, suggested_q1, suggested_q2, suggested_q3]\n",
    "    )\n",
    "\n",
    "    # Suggested question clicks\n",
    "    suggest_btn1.click(chat_stream, inputs=[suggested_q1, state, level], outputs=[answer_box, state, question])\n",
    "    suggest_btn2.click(chat_stream, inputs=[suggested_q2, state, level], outputs=[answer_box, state, question])\n",
    "    suggest_btn3.click(chat_stream, inputs=[suggested_q3, state, level], outputs=[answer_box, state, question])\n",
    "\n",
    "    # Clear button\n",
    "    clear_btn.click(\n",
    "        fn=lambda: (\"\", [], \"\", \"\", \"\", \"\", \"\", \"\", \"\"),\n",
    "        inputs=[],\n",
    "        outputs=[answer_box, state, question, suggest_btn1, suggest_btn2, suggest_btn3, suggested_q1, suggested_q2, suggested_q3]\n",
    "    )\n",
    "\n",
    "demo.launch(inbrowser=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c41f0b-0f30-48b6-9464-10c3ce8ee3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127b69a-48b3-48c1-a063-4b9eb804dad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
