{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db28d83f-1290-4712-9a80-5e272f928152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python: D:\\LONGSPUR\\TASK\\AI_buddy_model\\buddyvenv\\Scripts\\python.exe\n",
      "Virtual Env: D:\\LONGSPUR\\TASK\\AI_buddy_model\\buddyvenv\n",
      "Working Dir: D:\\LONGSPUR\\TASK\\AI_buddy_model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "print(f\"\"\"\n",
    "Python: {sys.executable}\n",
    "Virtual Env: {sys.prefix}\n",
    "Working Dir: {os.getcwd()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682e529a-275e-4a1f-b09d-1075af280fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LONGSPUR\\TASK\\AI_buddy_model\\buddyvenv\\Lib\\site-packages\\pandas\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__file__)  # Should show buddyvenv path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1f9ff1-c708-4b7b-ac76-a519fdba4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2163967-2d95-4273-aa0e-261966d0bc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --force-reinstall python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71046d2c-ef8a-402b-990c-f5dcfe4aafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a0f2a9-7f45-4aa3-9193-a9c2a0c4093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')  \n",
    "if openai_api_key:\n",
    "    print(\"API key loaded successfully!\")\n",
    "else:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf98451f-4a29-4b55-b697-755fd890ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.69.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: D:\\LONGSPUR\\TASK\\AI_buddy_model\\buddyvenv\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: langchain-openai\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc71bb9-4766-4c64-9c2f-702197087420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "#from langchain_core.documents import Document\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c797f683-cec8-4e79-978f-ccddf3e9c45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca32697-d82a-42a4-a9f2-e80716808460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18f8d74-85b2-41f6-be51-1dd20c773a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.preprocess_pdf import extract_text_from_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf3824c-e46e-4a69-a2b9-d588af160902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyond Earth12Chapter\n",
      "Nubra is a beautiful region in Ladakh. An eleven-year old \n",
      "girl Yangdol and her twin brother Dorjay live in one of the villages of this region. \n",
      "They love their \n",
      "surroundings—the majestic mountain peaks, and the glaciers, but their favourite is the night sky when the entire sky is lit up with thousands of stars (Fig. 12.1). The weather in Nubra is almost cloudless. With almost no air or light pollution, the night sky is very clearly visible. Night after night, Yangdol and Dorjay observe the stars and experience an immense sense of awe.\n",
      "Fig. 12.1: The beauty of night sky from a very dark \n",
      "location in Ladakh, India\n",
      "Nubra in Ladakh, India\n",
      "Chapter 12.indd   231 10-07-2024   18:13:26\n",
      " Curiosity | Textbook of Science | Grade 6\n",
      "232Growing up, Yangdol and Dorjay have been hearing \n",
      "interesting stories about stars from their elders. They have \n",
      "heard how some particular stars in the clear skies helped the caravans passing through Nubra in finding direction in the ancient day\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_path = os.path.join(\"knowledge-base\", \"textbook.pdf\")\n",
    "pdf_path = os.path.abspath(base_path) \n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "if text:\n",
    "    print(text[:100])\n",
    "else:\n",
    "    print(\"No text extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec6c42a7-f550-4477-9875-47320c63f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_ADVANCED = False  \n",
    "MODEL = \"gpt-4o-mini\" if USE_ADVANCED else \"gpt-3.5-turbo\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "818bb03f-f400-437f-8c8a-3179185ea9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff3c4f09-0dfb-4110-ac49-c879bc83337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     D:\\LONGSPUR\\TASK\\AI_buddy_model\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk_data_dir = \"D:\\\\LONGSPUR\\\\TASK\\\\AI_buddy_model\\\\nltk_data\"\n",
    "nltk.download('punkt', download_dir=nltk_data_dir)\n",
    "nltk.data.path.append(nltk_data_dir)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69a33c8-8de6-48fd-889a-7414fb218eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiktoken import encoding_for_model\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0013c404-24bd-4200-9598-e4f88ac29b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 9\n",
      "First Chunk:\n",
      "{'text': 'Beyond Earth12Chapter Nubra is a beautiful region in Ladakh. An eleven-year old  girl Yangdol and her twin brother Dorjay live in one of the villages of this region. They love their  surroundings—the majestic mountain peaks, and the glaciers, but their favourite is the night sky when the entire sky is lit up with thousands of stars (Fig. 12.1). The weather in Nubra is almost cloudless. With almost no air or light pollution, the night sky is very clearly visible. Night after night, Yangdol and Dorjay observe the stars and experience an immense sense of awe. Fig. 12.1: The beauty of night sky from a very dark  location in Ladakh, India Nubra in Ladakh, India Chapter 12.indd   231 10-07-2024   18:13:26  Curiosity | Textbook of Science | Grade 6 232Growing up, Yangdol and Dorjay have been hearing  interesting stories about stars from their elders. They have  heard how some particular stars in the clear skies helped the caravans passing through Nubra in finding direction in the ancient days. They wonder how far away and how big the stars are. They also enjoy trying to find some patterns among the stars that remind them of familiar objects. Have you ever looked at the stars in the night sky and tried to connect them with imaginary lines, just like dots and lines in a drawing? Activity 12.1: Let us draw  \\x8bFig. 12.2 shows bright stars in one part of the night sky. \\x8bLook at it carefully and try to imagine a pattern formed by a group of stars. \\x8bDraw lines to connect the stars and make the pattern. \\x8bThink of an animal or an object that is similar to the pattern drawn by you. Write its name near your pattern.12.1 Stars and Constellations At night, when we look up at the sky, we see many stars. Some stars are bright and others  are dim. Stars shine with their own light. Some groups of stars appear to form  patterns which are like shapes of familiar things. Long ago, when watching stars in the night sky was a favourite pastime of our ancestors, they identified these star patterns with animals, things or characters in stories. Many cultures had names for patterns based on their own stories. These imaginary shapes helped them in recognising stars in the sky. Recognising stars and their patterns was a useful skill  for navigation in the olden times. Before the arrival of modern technology or even before the invention of the magnetic compass, it helped people, particularly sailors and travellers, in finding directions at sea or on land. It is still used in emergencies as a backup method. In earlier times, groups of stars forming patterns were  called constellations. Currently, the regions of sky, which include these groups of stars, are defined as constellations. However , since in constellations, the patterns of stars are often the most prominent, the term constellation is still  commonly used for these groups of stars. Fig. 12.2: A part of the night sky  \\x8bRepeat the above steps and make some more patterns. \\x8bNow think of an interesting story about your patterns. Compare your  patterns with the patterns drawn by your friends. Are the patterns same or different? Narrate your story to others and listen to their stories. Do you notice that everyone’s patterns, names and stories are different? Is it not fun? Chapter 12.indd   232 10-07-2024   18:13:27 Beyond Earth233Growing up, Yangdol and Dorjay have been hearing  interesting stories about stars from their elders. They have  heard how some particular stars in the clear skies helped the caravans passing through Nubra in finding direction in the ancient days. They wonder how far away and how big the stars are. They also enjoy trying to find some patterns among the stars that remind them of familiar objects. Have you ever looked at the stars in the night sky and tried to connect them with imaginary lines, just like dots and lines in a drawing? Activity 12.1: Let us draw  \\x8bFig. 12.2 shows bright stars in one part of the night sky. \\x8bLook at it carefully and try to imagine a pattern formed by a group of stars. \\x8bDraw lines to connect the stars and make the pattern. \\x8bThink of an animal or an object that is similar to the pattern drawn by you. Write its name near your pattern.12.1 Stars and Constellations At night, when we look up at the sky, we see  many stars. Some stars are bright and others  are dim. Stars shine with their own light.', 'tokens': 988, 'chunk_id': 0, 'page_number': 1}\n"
     ]
    }
   ],
   "source": [
    "from scripts.chunking import dynamic_chunking_with_metadata\n",
    "chunks = dynamic_chunking_with_metadata(text, token_limit=1000, model=\"cl100k_base\",page_number=1)\n",
    "print(f\"Total Chunks: {len(chunks)}\")\n",
    "print(\"First Chunk:\")\n",
    "print(chunks[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f75cf76-73f9-431d-828a-b29381c9ba5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>Beyond Earth12Chapter Nubra is a beautiful reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>963</td>\n",
       "      <td>Some groups of stars appear to form  patterns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>970</td>\n",
       "      <td>12.4: Big Dipper , Little Dipper  and Pole Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>996</td>\n",
       "      <td>Activity 12.3: Let us try to identify   In In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>More to  know! There are many more objects  in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>958</td>\n",
       "      <td>Many Higher Education  Institutions conduct ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>996</td>\n",
       "      <td>Few other comets get broken up, or fall into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>978</td>\n",
       "      <td>(ii)  Make two similar riddles b y yourself. 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>359</td>\n",
       "      <td>Chapter 12.indd   252 10-07-2024   18:20:23 It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Chunk ID  Tokens                                            Preview\n",
       "0         0     988  Beyond Earth12Chapter Nubra is a beautiful reg...\n",
       "1         1     963  Some groups of stars appear to form  patterns ...\n",
       "2         2     970  12.4: Big Dipper , Little Dipper  and Pole Sta...\n",
       "3         3     996  Activity 12.3: Let us try to identify   In In...\n",
       "4         4    1000  More to  know! There are many more objects  in...\n",
       "5         5     958  Many Higher Education  Institutions conduct ni...\n",
       "6         6     996  Few other comets get broken up, or fall into t...\n",
       "7         7     978  (ii)  Make two similar riddles b y yourself. 3...\n",
       "8         8     359  Chapter 12.indd   252 10-07-2024   18:20:23 It..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Total Chunks: 9\n",
      "🔠 Total Tokens: 8208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def visualize_chunks(chunks):\n",
    "    df = pd.DataFrame([{\n",
    "        \"Chunk ID\": c[\"chunk_id\"],\n",
    "        \"Tokens\": c[\"tokens\"],\n",
    "        \"Preview\": c[\"text\"][:100] + \"...\" if len(c[\"text\"]) > 100 else c[\"text\"]\n",
    "    } for c in chunks])\n",
    "\n",
    "    display(df)\n",
    "    print(f\"📦 Total Chunks: {len(chunks)}\")\n",
    "    print(f\"🔠 Total Tokens: {sum(c['tokens'] for c in chunks)}\")\n",
    "\n",
    "visualize_chunks(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01471483-854a-4f59-a82b-21fbd2063fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade chromadb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23279b09-fbe4-4fe9-8d07-e00aa9890efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b29d835a-2b27-480c-bd91-b04e9d3139b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de5e6870-e994-42ec-8007-fea82f77dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aaad616-39a2-4876-b033-b4e1fec73ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "⚠️ ChromaDB exists at 'vector_db'. Do you want to delete it? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipped deletion. Existing DB will be reused.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    confirm = input(f\"⚠️ ChromaDB exists at '{db_name}'. Do you want to delete it? (y/n): \")\n",
    "    if confirm.lower() == \"y\":\n",
    "        Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "        print(f\"🗑️ ChromaDB at '{db_name}' has been deleted.\")\n",
    "    else:\n",
    "        print(\"❌ Skipped deletion. Existing DB will be reused.\")\n",
    "else:\n",
    "    print(f\"✅ No existing ChromaDB found at '{db_name}'. Starting fresh.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dad69b3-9922-4fa8-9331-ff4854d00188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b9089c-76c1-4aa8-8acf-92e70f1a435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 9 LangChain Documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=chunk[\"text\"],\n",
    "        metadata={\n",
    "            \"chunk_id\": chunk[\"chunk_id\"],\n",
    "            \"page_number\": chunk[\"page_number\"],\n",
    "            \"tokens\": chunk[\"tokens\"]  # Optional: track token count\n",
    "        }\n",
    "    )\n",
    "    for chunk in chunks\n",
    "]\n",
    "\n",
    "print(f\"✅ Created {len(documents)} LangChain Documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5679f1d6-5a31-4faf-a9dd-3327afc825b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Documents added to ChromaDB successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_directory = \"./vector_db\"\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./vector_db\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"✅ Documents added to ChromaDB successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe13920a-b36f-4b63-b982-a3c650b250e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-openai chromadb openai tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b56bac8-7334-4816-aa17-24220b02ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install rank_bm25 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c41a1a9-1eed-4c8a-929f-e5e272d41ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "bm25_retriever.k = 3\n",
    "vector_retriever.search_kwargs['k'] = 3\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "\n",
    "vector_retriever = vectorstore.as_retriever()\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.5, 0.5]  # You can tune this ratio\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c724c82-b4d7-458c-827d-27943b9fc62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "759f8079-3d0c-4b2c-93ef-09b0f2f1846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o-mini\")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=hybrid_retriever,\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1833e9ce-73a4-4a89-95bf-07a2a2e3296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "query = \"is pdf contains image representation of solar system\"\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3929e23-57d6-443e-9406-ba1318ac7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    \"textbook\": \"Answer this like a 6th-grade textbook would:\",\n",
    "    \"detailed\": \"Explain this with step-by-step detail, examples, and analogies:\",\n",
    "    \"advanced\": \"Answer this with deeper real-world applications and fun facts:\"\n",
    "}\n",
    "\n",
    "def build_prompt(question, level):\n",
    "    return f\"{PROMPTS.get(level, '')} {question.strip()}\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8dcc0c74-1e09-4266-a092-5d8577fff89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUGGEST_QUESTIONS_PROMPT = \"\"\"You're a helpful learning assistant.\n",
    "\n",
    "Based on the following answer, generate 3 thoughtful follow-up questions a 6th-grade student might ask next. Format each question on a new line:\n",
    "\n",
    "Answer:\n",
    "{content}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87a60515-eed5-41fb-83f2-23f21f34b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suggested_questions(content):\n",
    "    prompt = SUGGEST_QUESTIONS_PROMPT.format(content=content.strip())\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Split by lines and clean each one\n",
    "    suggestions = response.content.strip().split(\"\\n\")\n",
    "\n",
    "    # Clean common leading characters and whitespace\n",
    "    cleaned = [\n",
    "        s.strip(\" -•123.\").strip()\n",
    "        for s in suggestions\n",
    "        if s.strip() and len(s.strip()) > 5  # Optional: ignore tiny garbage\n",
    "    ]\n",
    "\n",
    "    # Optional: limit to top 3 or 5\n",
    "    return cleaned[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b72e1c-540b-43e5-9cd7-655bae158691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48d9529d-88fc-4a21-99e9-7322b86abe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Answer this like a 6th-grade textbook would: what is solar systems?\n",
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Explain this with step-by-step detail, examples, and analogies: what is solar systems?\n",
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Answer this with deeper real-world applications and fun facts: what is solar systems?\n",
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Answer this with deeper real-world applications and fun facts: How do scientists determine if a planet in another solar system is in the \"Goldilocks zone\"?\n",
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Answer this with deeper real-world applications and fun facts: Is there a way I could help you find the answer?\n",
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Answer this like a 6th-grade textbook would: What should I do if I have a question that no one knows the answer to?\n",
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Answer this like a 6th-grade textbook would: solar systems?\n",
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Answer this like a 6th-grade textbook would: What are some differences between the planets in our Solar System?\n",
      "📤 FINAL PROMPT SENT TO LLM:\n",
      "Answer this like a 6th-grade textbook would: What are some interesting facts about the moons of the outer planets?\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def chat(message, history, level):\n",
    "    if not message or len(message.strip()) < 4:\n",
    "        return \"🙁 Please ask a proper question so I can help!\", history, message, gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
    "\n",
    "    prompt = build_prompt(message, level)\n",
    "    print(\"📤 FINAL PROMPT SENT TO LLM:\")\n",
    "    print(prompt)  # ✅ Safe here\n",
    "\n",
    "    result = conversation_chain.invoke({\"question\": prompt})\n",
    "    suggestions = generate_suggested_questions(result[\"answer\"])\n",
    "\n",
    "    s1 = gr.update(value=suggestions[0], visible=True) if len(suggestions) > 0 else gr.update(visible=False)\n",
    "    s2 = gr.update(value=suggestions[1], visible=True) if len(suggestions) > 1 else gr.update(visible=False)\n",
    "    s3 = gr.update(value=suggestions[2], visible=True) if len(suggestions) > 2 else gr.update(visible=False)\n",
    "\n",
    "    return result[\"answer\"], history + [(message, result[\"answer\"])], message, s1, s2, s3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks(css=\"\"\"\n",
    "body {\n",
    "    background-color: #121212;\n",
    "    font-family: 'Segoe UI', sans-serif;\n",
    "}\n",
    "\n",
    ".gr-button {\n",
    "    font-size: 16px !important;\n",
    "    padding: 14px !important;\n",
    "    border-radius: 10px;\n",
    "}\n",
    "\n",
    ".gr-button-primary {\n",
    "    background-color: #4CAF50 !important;\n",
    "    color: white !important;\n",
    "}\n",
    "\n",
    ".suggested-btn {\n",
    "    width: 100% !important;\n",
    "    margin-top: 10px !important;\n",
    "    background-color: #e8eaf6 !important;\n",
    "    color: #1a237e !important;\n",
    "    padding: 16px !important;\n",
    "    text-align: left !important;\n",
    "    font-size: 16px !important;\n",
    "    font-weight: 500 !important;\n",
    "    border: none !important;\n",
    "    box-shadow: 0px 1px 3px rgba(0,0,0,0.1);\n",
    "    transition: background-color 0.2s ease;\n",
    "}\n",
    "\n",
    ".suggested-btn:hover {\n",
    "    background-color: #d1d9ff !important;\n",
    "}\n",
    "\"\"\") as demo:\n",
    "\n",
    "    gr.Markdown(\"### 👋 Welcome to Buddy AI: Your Learning Companion\")\n",
    "\n",
    "    question = gr.Textbox(label=\"Ask your question 👇\", lines=1, elem_id=\"question-box\")\n",
    "    level = gr.Dropdown(choices=[\"textbook\", \"detailed\", \"advanced\"], value=\"textbook\", label=\"Answer Level 🎯\")\n",
    "    answer_box = gr.Textbox(label=\"🧠 Buddy's Answer\", lines=8, interactive=False)\n",
    "    suggested_html = gr.HTML(label=\"🤔 Suggested Questions\")\n",
    "    state = gr.State([])\n",
    "\n",
    "    suggest_btn1 = gr.Button(visible=False, interactive=True, elem_classes=\"suggested-btn\")\n",
    "    suggest_btn2 = gr.Button(visible=False, interactive=True, elem_classes=\"suggested-btn\")\n",
    "    suggest_btn3 = gr.Button(visible=False, interactive=True, elem_classes=\"suggested-btn\")\n",
    "\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\", elem_classes=\"gr-button-primary\")\n",
    "        clear_btn = gr.Button(\"Clear\")\n",
    "\n",
    "    # Submit typed question\n",
    "    submit_btn.click(\n",
    "        fn=chat,\n",
    "        inputs=[question, state, level],\n",
    "        outputs=[\n",
    "            answer_box,\n",
    "            state,\n",
    "            question,\n",
    "            suggest_btn1,\n",
    "            suggest_btn2,\n",
    "            suggest_btn3\n",
    "        ]\n",
    ")\n",
    "\n",
    "\n",
    "    # Clear all fields\n",
    "    clear_btn.click(\n",
    "        fn=lambda: (\"\", [], \"\", \"\"),\n",
    "        inputs=[],\n",
    "        outputs=[answer_box, state, question, suggested_html]\n",
    "    )\n",
    "\n",
    "    # Suggested follow-up question clicks\n",
    "    for btn in [suggest_btn1, suggest_btn2, suggest_btn3]:\n",
    "        btn.click(\n",
    "            fn=lambda btn_text, history, level: chat(btn_text, history, level),\n",
    "            inputs=[btn, state, level],\n",
    "            outputs=[answer_box, state, question, suggest_btn1, suggest_btn2, suggest_btn3]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "demo.launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472cb04e-c42b-47ec-942c-db0286393b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c41f0b-0f30-48b6-9464-10c3ce8ee3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
